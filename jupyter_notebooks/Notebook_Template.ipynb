{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **(RETAIL SALES ETL AND ANALYSIS NOTEBOOK)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "The objective of this notebook is to extract, clean, transform, and analyse retail sales data in order to identify sales trends, evaluate the impact of promotional markdowns, and compare holiday versus non-holiday sales performance.\n",
        "The notebook supports data-driven insights to assist retail and marketing stakeholders in strategic decision-making.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "To run this notebook, the following inputs are required:\n",
        "\n",
        "- Raw retail sales dataset stored in the data/raw/ directory\n",
        "\n",
        "- Data fields including:\n",
        "\n",
        "    . Weekly sales figures\n",
        "\n",
        "    . Store identifiers and attributes (store type, size, region)\n",
        "\n",
        "    . Promotional markdown values (MarkDown1â€“MarkDown5)\n",
        "\n",
        "    . Holiday indicators\n",
        "\n",
        "- Python libraries:\n",
        "\n",
        "    . pandas\n",
        "\n",
        "    . numpy\n",
        "\n",
        "    . matplotlib\n",
        "\n",
        "    . seaborn\n",
        "\n",
        "    . plotly\n",
        "\n",
        "## Outputs\n",
        "\n",
        "By the end of this notebook, the following outputs are generated:\n",
        "\n",
        "- A cleaned and transformed retail sales dataset saved to data/processed/\n",
        "\n",
        "- Engineered features such as total promotional markdowns and holiday indicators\n",
        "\n",
        "- Descriptive statistics summarising sales performance\n",
        "\n",
        "- Visualisations illustrating:\n",
        "\n",
        "    . Sales trends over time\n",
        "\n",
        "    . Store and regional comparisons\n",
        "\n",
        "    . Impact of promotional markdowns\n",
        "\n",
        "    . Holiday vs non-holiday sales performance\n",
        "\n",
        "- Business-focused insights and conclusions documented within the notebook\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "All analysis steps are documented using Markdown cells to ensure transparency and reproducibility.\n",
        "\n",
        "Limitations of the data and analysis are acknowledged, and potential future improvements are discussed.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/isaacola/Documents/vscode-project/retail-sales/jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/isaacola/Documents/vscode-project/retail-sales'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Section 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ETL Process\n",
        "\n",
        "In this section, we perform Extract, Transform, Load (ETL) operations on the retail sales data:\n",
        "\n",
        "- **Extract**: Load raw CSV files (sales, stores, features).\n",
        "- **Transform**: Merge datasets, handle missing values, convert data types, engineer features.\n",
        "- **Load**: Save the cleaned dataset to the clean-data directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ETL completed. Cleaned data saved to dataset/clean-data/cleaned_sales_data.csv\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Extract: Load raw data\n",
        "sales_df = pd.read_csv('dataset/raw-data/sales-data-set.csv')\n",
        "stores_df = pd.read_csv('dataset/raw-data/stores-data-set.csv')\n",
        "features_df = pd.read_csv('dataset/raw-data/Features-data-set.csv')\n",
        "\n",
        "# Transform: Merge datasets\n",
        "# Merge sales with stores\n",
        "merged_df = pd.merge(sales_df, stores_df, on='Store', how='left')\n",
        "\n",
        "# Merge with features on Store and Date\n",
        "merged_df = pd.merge(merged_df, features_df, on=['Store', 'Date'], how='left')\n",
        "\n",
        "# Convert Date to datetime\n",
        "merged_df['Date'] = pd.to_datetime(merged_df['Date'], format='%d/%m/%Y')\n",
        "\n",
        "# Handle missing values: Replace 'NA' with NaN and fill MarkDowns with 0\n",
        "merged_df.replace('NA', np.nan, inplace=True)\n",
        "markdown_cols = ['MarkDown1', 'MarkDown2', 'MarkDown3', 'MarkDown4', 'MarkDown5']\n",
        "merged_df[markdown_cols] = merged_df[markdown_cols].fillna(0)\n",
        "\n",
        "# Feature engineering: Total MarkDown\n",
        "merged_df['Total_MarkDown'] = merged_df[markdown_cols].sum(axis=1)\n",
        "\n",
        "# Ensure clean-data directory exists\n",
        "os.makedirs('dataset/clean-data', exist_ok=True)\n",
        "\n",
        "# Load: Save cleaned data\n",
        "merged_df.to_csv('dataset/clean-data/cleaned_sales_data.csv', index=False)\n",
        "\n",
        "print(\"ETL completed. Cleaned data saved to dataset/clean-data/cleaned_sales_data.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Section 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Section 2 content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* You may add as many sections as you want, as long as it supports your project workflow.\n",
        "* All notebook's cells should be run top-down (you can't create a dynamic wherein a given point you need to go back to a previous cell to execute some task, like go back to a previous cell and refresh a variable content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In cases where you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create your folder here\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": ".venv (3.12.8)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
